# Test Suite Handoff: mission-deck-compensation

**Date:** 2025-11-07
**Generated by:** Sofia (The Checker)
**Mission:** mission-deck-compensation
**Purpose:** Complete test suite ready for Rafael's implementation

---

## âœ… Test Suite Overview

I've generated **82 test cases** across 3 testing layers (backend, frontend, E2E) based on Inna's VALIDATION.md specifications. All tests are mapped to specific acceptance criteria from AC.md.

### Test Coverage Summary

**Backend Tests (pytest):** 47 tests
- Interaction tracking accuracy: 9 tests
- Earnings calculation correctness: 10 tests
- Mission fund management: 12 tests
- Payment trigger logic: 11 tests
- Performance benchmarks: 5 tests

**Frontend Tests (Vitest):** 23 tests
- Real-time earnings UI updates: 10 tests
- Mission claiming UI flow: 13 tests

**E2E Tests (Playwright):** 12 tests
- Complete job compensation flow: 1 test (comprehensive)
- Mission claiming and completion flow: 1 test (comprehensive)
- Edge cases and mobile responsiveness: 10 tests

---

## ğŸ“ Test Files Structure

```
tests/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ test_compensation_interactions.py      # T1: Interaction tracking (9 tests)
â”‚   â”œâ”€â”€ test_compensation_earnings.py          # T2: Earnings calculations (10 tests)
â”‚   â”œâ”€â”€ test_compensation_missions.py          # T3: Mission fund (12 tests)
â”‚   â””â”€â”€ test_compensation_payments.py          # T4: Payment triggers (11 tests)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ earnings-display.test.tsx              # T5: Real-time UI updates (10 tests)
â”‚   â””â”€â”€ mission-claiming.test.tsx              # T6: Mission UI flows (13 tests)
â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ compensation-flow.spec.ts              # T7-T8: End-to-end flows (12 tests)
â””â”€â”€ fixtures/
    â””â”€â”€ compensation_fixtures.py               # Test helpers and FalkorDB queries
```

---

## ğŸ”§ Setup Instructions

### 1. Install Dependencies

**Backend:**
```bash
pip install pytest pytest-cov requests
```

**Frontend:**
```bash
npm install vitest @testing-library/react @testing-library/user-event --save-dev
```

**E2E:**
```bash
npx playwright install
```

### 2. Environment Variables

Create `.env.test` with FalkorDB credentials:

```bash
FALKORDB_API_URL=https://mindprotocol.onrender.com/admin/query
FALKORDB_API_KEY=Sxv48F2idLAXMnvqQTdvlQ4gArsDVhK4ROGyU
GRAPH_NAME=scopelock
```

### 3. Verify Setup

```bash
# Backend
pytest tests/backend/test_compensation_interactions.py::TestInteractionTracking::test_interaction_increments_on_message_sent -v

# Frontend
npm test -- earnings-display.test.tsx -t "test_earnings_banner_displays_total"

# E2E
npx playwright test tests/e2e/compensation-flow.spec.ts -g "complete job compensation flow"
```

---

## ğŸš€ Running Tests

### Backend Tests (pytest)

**Run all backend tests:**
```bash
pytest tests/backend/ -v
```

**Run specific test file:**
```bash
pytest tests/backend/test_compensation_earnings.py -v
```

**Run specific test:**
```bash
pytest tests/backend/test_compensation_earnings.py::TestEarningsCalculation::test_earnings_formula_multiple_members -v
```

**With coverage:**
```bash
pytest tests/backend/ -v --cov=compensation --cov-report=html
```

---

### Frontend Tests (Vitest)

**Run all frontend tests:**
```bash
npm test -- tests/frontend/
```

**Run specific test file:**
```bash
npm test -- earnings-display.test.tsx
```

**Watch mode (for development):**
```bash
npm test -- earnings-display.test.tsx --watch
```

---

### E2E Tests (Playwright)

**Run all E2E tests:**
```bash
npx playwright test tests/e2e/compensation-flow.spec.ts
```

**Run specific test:**
```bash
npx playwright test tests/e2e/compensation-flow.spec.ts -g "complete job compensation flow"
```

**With UI (headed mode):**
```bash
npx playwright test tests/e2e/compensation-flow.spec.ts --headed
```

**Debug mode:**
```bash
npx playwright test tests/e2e/compensation-flow.spec.ts --debug
```

---

## ğŸ“‹ Test Execution Checklist (DoD)

Before handing off to Sofia for final QA, verify:

**Backend:**
- [ ] All 47 backend tests passing (100%)
- [ ] Coverage â‰¥ 95% for compensation module
- [ ] Performance benchmarks met (p95 < 200ms for earnings calculation)
- [ ] No FalkorDB query failures

**Frontend:**
- [ ] All 23 frontend tests passing (100%)
- [ ] Coverage â‰¥ 85% for compensation components
- [ ] Real-time updates < 500ms (verified in tests)
- [ ] No console errors during test runs

**E2E:**
- [ ] All 12 E2E tests passing (100%)
- [ ] Tests pass in both Chrome and Firefox
- [ ] Mobile viewport tests pass (320px width)
- [ ] No flaky tests (tests pass consistently 3/3 runs)

---

## ğŸ¯ TDD Workflow (IMPORTANT!)

**Rafael, your implementation must pass MY tests. This is Test-Driven Development.**

### Step 1: Run Tests (Before Coding)

```bash
# All tests should FAIL initially (no implementation yet)
pytest tests/backend/ -v
npm test -- tests/frontend/
npx playwright test tests/e2e/
```

**Expected:** All tests fail with "Module not found" or "Function not defined"

### Step 2: Implement Features

Generate implementation code per Inna's ALGORITHM.md to make tests pass.

**Order of implementation:**
1. **Backend first:** Implement compensation logic (interactions, earnings, missions, payments)
2. **Frontend second:** Implement UI components (earnings display, mission claiming)
3. **E2E last:** Deploy and verify complete flows

### Step 3: Run Tests After Each Feature

```bash
# After implementing interaction tracking
pytest tests/backend/test_compensation_interactions.py -v

# After implementing earnings calculation
pytest tests/backend/test_compensation_earnings.py -v

# After implementing mission fund
pytest tests/backend/test_compensation_missions.py -v
```

**Goal:** Each test file should pass 100% before moving to next

### Step 4: Fix Failures

When tests fail:
1. Read the test code to understand what it's checking
2. Check the assertion error message for specifics
3. Fix implementation to match expected behavior
4. Re-run test until it passes

**Example failure:**
```
FAILED test_compensation_earnings.py::test_earnings_formula_multiple_members
AssertionError: assert Decimal('299.99') == Decimal('300.00')
```

**Fix:** Check rounding logic in earnings calculation

### Step 5: Handoff to Sofia

When ALL tests pass:

```bash
# Final verification
pytest tests/backend/ -v --cov=compensation
npm test -- tests/frontend/
npx playwright test tests/e2e/
```

**Expected:** 82/82 tests passing âœ…

Then notify Sofia:

```
@Sofia â€” Implementation complete: mission-deck-compensation

Test suite results:
- Backend: 47/47 passing âœ…
- Frontend: 23/23 passing âœ…
- E2E: 12/12 passing âœ…
- Coverage: Backend 97%, Frontend 88%

Deployment URL: [production or preview URL]

Ready for your final QA verification.
```

---

## ğŸ” Test Details by Category

### T1: Interaction Tracking (9 tests)

**File:** `tests/backend/test_compensation_interactions.py`

**What it tests:**
- Messages increment interaction count correctly
- Interactions counted per-job only
- Multiple members tracked separately
- Messages outside job context not counted
- Duplicate message prevention
- Complete audit trail in FalkorDB

**Key assertions:**
- `assert get_interaction_count(job.id, member.id) == 1`
- `assert get_total_interactions(job.id) == 8`
- `assert len(events) == 10` (FalkorDB persistence)

---

### T2: Earnings Calculation (10 tests)

**File:** `tests/backend/test_compensation_earnings.py`

**What it tests:**
- Earnings formula correct for single/multiple members
- Earnings update when new interaction added
- Rounding to 2 decimal places
- Zero interactions = zero earnings
- Sum of all earnings = exactly team pool (no floating-point errors)
- Performance < 200ms

**Key assertions:**
- `assert earnings_a == Decimal("300.00")` (Formula correct)
- `assert earnings_a + earnings_b + earnings_c == team_pool` (Exact pool distribution)
- `assert duration_ms < 200` (Performance)

---

### T3: Mission Fund Management (12 tests)

**File:** `tests/backend/test_compensation_missions.py`

**What it tests:**
- Mission fund increases by 5% on job creation
- Mission fund decreases on completion
- Cannot claim with < 5 interactions
- Mission claim expires after 24 hours
- Cannot create mission if fund insufficient
- Mission fund rolls over between jobs

**Key assertions:**
- `assert new_balance == initial_balance + Decimal("50.00")` (5% contribution)
- `pytest.raises(ValueError, match="Need 5\\+ interactions")` (Minimum interactions)
- `assert status == "available"` (Expiry after 24h)

---

### T4: Payment Triggers (11 tests)

**File:** `tests/backend/test_compensation_payments.py`

**What it tests:**
- Only NLR can trigger payment
- Payment freezes interaction counts
- Payment calculates correct final shares
- Earnings move from potential to paid history
- Notifications sent to all contributors
- Cannot trigger payment without cash receipt

**Key assertions:**
- `pytest.raises(PermissionError, match="Only NLR")` (Authorization)
- `assert result["member_payments"][member_a.id] == Decimal("270.00")` (Correct shares)
- `assert get_job_status(job.id) == "paid"` (Status update)

---

### T5: Real-Time Earnings UI (10 tests)

**File:** `tests/frontend/earnings-display.test.tsx`

**What it tests:**
- Earnings banner displays total correctly
- Earnings update within 500ms when interaction added
- Job card shows interaction count and potential earning
- Loading state during update
- Error message on failed update

**Key assertions:**
- `expect(screen.getByText(/\$169\.00/)).toBeInTheDocument()`
- `await waitFor(() => {...}, { timeout: 500 })` (Performance)
- `expect(screen.getByTestId('loading-spinner')).toBeInTheDocument()` (Loading state)

---

### T6: Mission Claiming UI (13 tests)

**File:** `tests/frontend/mission-claiming.test.tsx`

**What it tests:**
- Mission card displays correctly
- Claim button disabled if insufficient interactions
- Claim button triggers confirmation modal
- Claimed mission shows "Mark Complete" button
- Mark complete requires proof upload
- Mission fund balance displays with tooltip

**Key assertions:**
- `expect(button).toBeDisabled()` (Insufficient interactions)
- `expect(screen.getByText(/Claim this mission for \$1\.00\?/)).toBeInTheDocument()` (Modal)
- `expect(screen.getByText(/proof required/i)).toBeInTheDocument()` (Validation)

---

### T7: Complete Job Flow (E2E)

**File:** `tests/e2e/compensation-flow.spec.ts`

**What it tests (end-to-end):**
1. Login as Member A
2. Create job ($1,500)
3. Send 5 messages to Rafael
4. Verify earnings update ($450)
5. Login as Member B, send 3 messages
6. Verify Member B earnings ($168.75)
7. Login as NLR, trigger payment
8. Verify payment breakdown correct
9. Verify job status = "Paid"
10. Verify notifications sent

**Key assertions:**
- `await expect(page.locator('[data-testid="potential-earning"]')).toHaveText('$450.00')`
- `await expect(page.locator('[data-testid="job-status"]')).toHaveText('Paid')`

---

### T8: Mission Claiming Flow (E2E)

**File:** `tests/e2e/compensation-flow.spec.ts`

**What it tests (end-to-end):**
1. Login as member with 10 interactions
2. Navigate to MISSIONS section
3. Claim "Write proposal" mission ($1)
4. Mark complete with proof URL
5. Login as NLR, approve mission
6. Verify earnings increased by $1
7. Verify mission fund decreased

**Key assertions:**
- `await expect(page.locator('[data-testid="mission-status-proposal"]')).toHaveText('Claimed by You')`
- `await expect(page.locator('[data-testid="total-earnings"]')).toContainText('+$1.00')`

---

## ğŸ› Common Issues and Fixes

### Backend Tests Failing

**Issue:** `FalkorDB query failed: 401 Unauthorized`
**Fix:** Check FALKORDB_API_KEY in `.env.test`

**Issue:** `assert 299.99 == 300.00` (rounding error)
**Fix:** Use `Decimal("0.01").quantize()` for rounding to 2 decimals

**Issue:** Tests pass individually but fail when run together
**Fix:** Ensure `clear_test_data()` is called in `setup_and_teardown` fixture

---

### Frontend Tests Failing

**Issue:** `expect(element).toBeInTheDocument() failed`
**Fix:** Check component imports and data-testid attributes match test expectations

**Issue:** `waitFor timeout exceeded`
**Fix:** Check if real-time update logic is implemented (< 500ms requirement)

---

### E2E Tests Failing

**Issue:** `Element not found: [data-testid="job-card-chatbot"]`
**Fix:** Ensure deployment URL is correct and app is running

**Issue:** Tests pass locally but fail in CI
**Fix:** Use `page.waitForSelector()` before assertions (wait for elements to load)

**Issue:** Flaky tests (pass sometimes, fail other times)
**Fix:** Add `await page.waitForTimeout(300)` after interactions to allow backend processing

---

## ğŸ“Š Success Criteria (from AC.md)

**All tests passing:**
- âœ… Backend: 47/47 tests
- âœ… Frontend: 23/23 tests
- âœ… E2E: 12/12 tests
- âœ… Total: 82/82 tests

**Coverage targets met:**
- âœ… Backend: â‰¥95% (compensation module)
- âœ… Frontend: â‰¥85% (compensation components)

**Performance benchmarks met:**
- âœ… Interaction tracking: p95 < 500ms
- âœ… Earnings calculation: p95 < 200ms
- âœ… UI update latency: p95 < 500ms

**Zero critical bugs in tests:**
- âœ… All assertions pass
- âœ… No timeout failures
- âœ… No flaky tests (consistent 3/3 runs)

---

## ğŸ¤ Handoff Notes

**Rafael:**

Your implementation must make these tests pass. I've defined quality via these 82 test cases. Each test maps to specific acceptance criteria from Inna's AC.md.

**Key points:**
1. Tests are already complete and ready to run
2. Your code must pass ALL 82 tests (TDD: implementation makes tests pass)
3. Run tests frequently during implementation (test-driven approach)
4. When all tests pass locally, deploy and notify me for final QA

**If tests are unclear:**
- Read the test code (it shows exactly what's expected)
- Check VALIDATION.md for test scenario descriptions
- Check AC.md for acceptance criteria details
- Ask me if specific test logic needs clarification

**After you finish implementation:**
Hand off to me with:
- Deployment URL
- Test results (all passing)
- Coverage reports
- Any edge cases you discovered

I'll run the full test suite against your deployment + verify DoD checklist + check for bugs.

Good luck! The tests define the target - make them green! ğŸ¯

---

**Generated by:** Sofia Chen â€” "The Checker"
**Date:** 2025-11-07
**Test Suite Version:** 1.0
